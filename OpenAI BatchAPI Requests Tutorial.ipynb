{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Requests with OpenAI API\n",
    "\n",
    "This notebook demonstrates how to efficiently process multiple prompts at once using OpenAI's Batch API.  \n",
    "  \n",
    "**Note**: Batch responses may take up to 24 hours to be processed by OpenAI.\n",
    "  \n",
    "  \n",
    "### **Step 1: Prepare JSONL File**\n",
    "To use OpenAI's Batch API, you need to provide prompts in a JSONL (JSON Lines) format.  \n",
    "Assuming you have a CSV file that includes two columns:  \n",
    "- prompts \n",
    "- IDs corresponding to each prompt (needed to retreive its response later)  \n",
    "\n",
    "CSV file content should be structured as follows:\n",
    "```\n",
    "IDs,Prompts\n",
    "request-1,\"Once upon a time,\"\n",
    "request-2,\"Translate Good morning to French.\"\n",
    "request-3,\"Write a poem about circles.\"\n",
    "```\n",
    "then use the following code to make a `JSONL` file. (Batch API accepts only JSONL file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file_name = 'prompts.csv'\n",
    "csv_file_directory = '.'\n",
    "\n",
    "# Constructing the file paths\n",
    "csv_file = os.path.join(csv_file_directory, csv_file_name)\n",
    "input_jsonl_file = os.path.join(csv_file_directory, csv_file_name.replace('csv', 'jsonl'))\n",
    "\n",
    "# Model configuration\n",
    "model = \"gpt-4-turbo\"\n",
    "max_tokens = 20\n",
    "temperature = 1\n",
    "system_message = \"You are a helpful assistant.\"\n",
    "\n",
    "def csv_to_jsonl(csv_file, jsonl_file, model, max_tokens=4096, temperature=1, system=\"You are a helpful assistant.\"):\n",
    "    \"\"\"Convert a CSV file to JSON Lines (JSONL) for batch requests using OpenAI API.\"\"\"\n",
    "    with open(csv_file, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        with open(jsonl_file, 'w', encoding='utf-8') as jsonlfile:\n",
    "            for row in reader:\n",
    "                custom_id = row['IDs']\n",
    "                user_message = row['Prompts']\n",
    "                data = construct_json_line(custom_id, model, user_message, system, max_tokens, temperature)\n",
    "                jsonlfile.write(json.dumps(data) + '\\n')\n",
    "\n",
    "def construct_json_line(custom_id, model, user_message, system_message, max_tokens, temperature):\n",
    "    \"\"\"Construct a JSON line for a chat completion request.\"\"\"\n",
    "    return {\n",
    "        \"custom_id\": custom_id, \n",
    "        \"method\": \"POST\", \n",
    "        \"url\": \"/v1/chat/completions\", \n",
    "        \"body\": {\n",
    "            \"model\": model, \n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": temperature,\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Convert CSV to JSONL\n",
    "csv_to_jsonl(csv_file, input_jsonl_file, model, max_tokens, temperature, system_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>**Optional**</u>:\n",
    "If your prompts in the JSONL file exceeds the maximum limit of tokens per day (900,000 TPD for tier 1), you can split the prompts in the JSONL file into multiple files, and batch them sequentially.  \n",
    "  \n",
    "If you receive this error for example:  \n",
    "```\n",
    "BatchError(code=‘token_limit_exceeded’, line=None, message='Enqueued token limit reached ...\n",
    "```\n",
    "in this case, you can use the following code to split the JSONL file.  \n",
    "  \n",
    "Specify `lines_per_file` based on the number of tokens in your prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "lines_per_file = 1    # Adjust as needed\n",
    "input_jsonl_file = './prompts.jsonl'\n",
    "splitted_files_directory = \"./Batch_Prompts\"\n",
    "\n",
    "def split_file(input_file_path, output_directory, lines_per_file):\n",
    "    \"\"\"Split lines into multiple files with a specified maximum number of lines per file.\"\"\"\n",
    "    os.makedirs(output_directory, exist_ok=True)        # Ensure the output directory exists, create if not \n",
    "    with open(input_file_path, \"r\") as infile:\n",
    "        lines = infile.readlines()\n",
    "\n",
    "    # Calculate the number of output files needed\n",
    "    num_files = (len(lines) + lines_per_file - 1) // lines_per_file\n",
    "\n",
    "    # Write lines to each output file\n",
    "    for i in range(num_files):\n",
    "        start_index = i * lines_per_file\n",
    "        end_index = min((i + 1) * lines_per_file, len(lines))\n",
    "        output_filename = f\"prompts-batch_{i+1}.jsonl\"\n",
    "        with open(os.path.join(output_directory, output_filename), \"w\") as outfile:\n",
    "            outfile.writelines(lines[start_index:end_index])\n",
    "\n",
    "split_file(input_jsonl_file, splitted_files_directory, lines_per_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Upload JSONL File(s)**\n",
    "\n",
    "There are two options to upload a file:\n",
    "\n",
    "1. **Via OpenAI Account**: Follow these steps:\n",
    "    - In OpenAI account dashboard:\n",
    "    - Navigate to [Storage](https://platform.openai.com/storage) section on the left sidebar.\n",
    "    - Click on **+ Upload** button at the top right.\n",
    "    - Select the file(s) and click on **Upload**.\n",
    "2. **Using Python Script**: Execute the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ID for prompts.jsonl: file-YqKy1G5WWVIwXngvhqH4Bc7v\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# batch_files_directory = \"./Batch_Prompts\"     # if you have multiple JSONL files\n",
    "batch_files_directory = \".\"               # if you have one JSONL file\n",
    "\n",
    "def upload_file(file_path):\n",
    "    '''Upload a JSONL file and return the file ID from OpenAI's server.'''\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            response = client.files.create(\n",
    "                file=file,\n",
    "                purpose=\"batch\"\n",
    "            )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# Get the list of JSONL files in the directory\n",
    "jsonl_files = [file for file in os.listdir(batch_files_directory) if file.endswith(\".jsonl\")]\n",
    "\n",
    "# Upload each JSONL file\n",
    "for jsonl_file in jsonl_files:\n",
    "    jsonl_batch_file_path = os.path.join(batch_files_directory, jsonl_file)\n",
    "    response = upload_file(jsonl_batch_file_path)\n",
    "    if response:\n",
    "        try:\n",
    "            input_file_id = response.id\n",
    "            print(f\"File ID for {jsonl_file}: {input_file_id}\")\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display List of Files in OpenAI Account\n",
    "This includes uploaded files, as well as output files generated by OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: file-YqKy1G5WWVIwXngvhqH4Bc7v | Purpose: batch        | Created at: 2024-04-28 09:28:24 | File Name: prompts.jsonl  \n"
     ]
    }
   ],
   "source": [
    "# List of available files \n",
    "from datetime import datetime\n",
    "\n",
    "def convert_timestamp(timestamp):\n",
    "    return datetime.fromtimestamp(timestamp) if timestamp is not None else None\n",
    "\n",
    "try:\n",
    "    list_files = client.files.list(\n",
    "        # purpose=\"batch\"       # specify purpose of file (batch, fine-tuning, assistant, etc).\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)   \n",
    "\n",
    "for i in range(len(list_files.data)):\n",
    "    file_data = list_files.data[i]\n",
    "    print(f\"File: {file_data.id:<15} | Purpose: {file_data.purpose:<12} | Created at: {convert_timestamp(file_data.created_at)} | File Name: {file_data.filename:<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete a File\n",
    "You can delete a file by passing its file ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete a file\n",
    "delete_file_id = \"file-xxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "try:\n",
    "    response = client.files.delete(delete_file_id)\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(e) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Create a Batch**\n",
    "\n",
    "(If you have multiple batch files to process, execute them sequentially to avoid reaching the Max Tokens per Day limit.)  \n",
    "  \n",
    "There are two options to create a batch request:\n",
    "\n",
    "1. **Via OpenAI Account**: Follow these steps:\n",
    "    - Access OpenAI account dashboard.\n",
    "    - Navigate to [Batch](https://platform.openai.com/batch) section on the left sidebar.\n",
    "    - Click on **+ Create** button at the top right.\n",
    "    - Upload the file and click on **Create**.\n",
    "2. **Using Python Script**: Execute the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch file name: prompts.jsonl\n",
      "Batch status: validating\n",
      "Batch ID: batch_CmmnPNarIuLiqqe031MwFMXR\n"
     ]
    }
   ],
   "source": [
    "# input_file_id = \"file-xxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "def create_batch(input_file_id, client):\n",
    "    \"\"\"Create a batch request and return the response.\"\"\"\n",
    "    try:\n",
    "        batch_response = client.batches.create(\n",
    "            input_file_id=input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\"\n",
    "        )\n",
    "        return batch_response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# Execute the batch creation\n",
    "batch_response = create_batch(input_file_id, client)\n",
    "\n",
    "# Display batch information\n",
    "if batch_response:\n",
    "    try:\n",
    "        file_name = client.files.retrieve(input_file_id).filename\n",
    "        print(\"Batch file name:\", file_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving file name: {e}\")\n",
    "    print(\"Batch status:\", batch_response.status)\n",
    "    if batch_response.id:\n",
    "        batch_id = batch_response.id\n",
    "        print(\"Batch ID:\", batch_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4: Monitor and Retrieve Batch Information**\n",
    "\n",
    "Again you have two options to monitor a batch request:\n",
    "\n",
    "1. **Via OpenAI Account**: Follow these steps:\n",
    "    - Access OpenAI account dashboard.\n",
    "    - Navigate to [Batch](https://platform.openai.com/batch) section on the left sidebar.\n",
    "    - Click on the desired batch ID (e.g., `batch_xxxxxxxxxxxxxxxxxxxxxxxx`).\n",
    "    - Check the status.\n",
    "2. **Using Python Script**: Execute the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch status: in_progress\n",
      "Completed: 0     | Failed: 0     | Total: 3     \n",
      "\n",
      "Batch created at: 2024-04-28 09:46:45\n",
      "Batch expires at: 2024-04-29 09:46:45\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# batch_id = \"batch_xxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "def check_batch(batch_id):\n",
    "    try:\n",
    "        return client.batches.retrieve(batch_id)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred while retrieving batch:\", e)\n",
    "        return None\n",
    "\n",
    "def convert_timestamp(timestamp):\n",
    "    return datetime.fromtimestamp(timestamp) if timestamp is not None else None\n",
    "\n",
    "def print_label_and_timestamp(label, timestamp):\n",
    "    if timestamp is not None:\n",
    "        print(label + \":\", convert_timestamp(timestamp))\n",
    "\n",
    "batch_response = check_batch(batch_id)\n",
    "\n",
    "if batch_response:\n",
    "    print(\"Batch status:\", batch_response.status)\n",
    "    request_counts = batch_response.request_counts\n",
    "    print(f\"Completed: {request_counts.completed:<6}| Failed: {request_counts.failed:<6}| Total: {request_counts.total:<6}\\n\")\n",
    "\n",
    "    if batch_response.errors:\n",
    "        print(\"Batch error:\", batch_response.errors)\n",
    "    else:\n",
    "        event_names = ['created_at', 'expires_at', 'completed_at', 'expired_at', 'failed_at']\n",
    "        for event_name in event_names:\n",
    "            print_label_and_timestamp(f\"Batch {event_name.replace('_', ' ')}\", getattr(batch_response, event_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<u>Cancel</u> a Batch**\n",
    "Eiter:\n",
    "1. **Via OpenAI Account**: Follow these steps:\n",
    "    - Access OpenAI account dashboard.\n",
    "    - Navigate to [Batch](https://platform.openai.com/batch) section on the left sidebar.\n",
    "    - Click on the desired batch ID (e.g., `batch_xxxxxxxxxxxxxxxxxxxxxxxx`).\n",
    "    - Click on `Cancel`.\n",
    "  \n",
    "or  \n",
    "2. **Using Python Script**: Execute the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id = \"batch_xxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "batch_response = check_batch(batch_id)\n",
    "\n",
    "if batch_response:\n",
    "    print(\"Batch status:\", batch_response.status)\n",
    "    if batch_response.errors:\n",
    "        print(\"Batch error:\", batch_response.errors)\n",
    "    else:\n",
    "        cancel_response = client.batches.cancel(batch_id)\n",
    "        if cancel_response.cancelled_at is not None:\n",
    "            print(\"Batch canceled at:\", convert_timestamp(cancel_response.cancelled_at))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 5: Retreive Output File Content**\n",
    "\n",
    "Again there are two options to monitor a batch request:\n",
    "\n",
    "1. **Via OpenAI Account**: Follow these steps:\n",
    "    - Access OpenAI account dashboard.\n",
    "    - Navigate to [Storage](https://platform.openai.com/storage) section on the left sidebar.\n",
    "    - Click on the JSONL file name with the desired batch ID (e.g., `batch_xxxxxxxxxxxxxxxxxxxxxxxx_output.jsonl`).\n",
    "    - Download the JSONL file\n",
    "2. **Using Python Script**: Execute the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# batch_id = \"batch_xxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "output_file_directory = \"./Responses\"\n",
    "output_file_name = 'responses.jsonl'\n",
    "\n",
    "def check_batch(batch_id):\n",
    "    try:\n",
    "        return client.batches.retrieve(batch_id)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred while retrieving batch:\", e)\n",
    "        return None\n",
    "\n",
    "def extract_batch_num(file_name):\n",
    "    \"\"\"A function to extract batch number from file name if possible\"\"\"\n",
    "    try:\n",
    "        return int(file_name.split('_')[1].split('.')[0])\n",
    "    except (IndexError, ValueError):\n",
    "        return None\n",
    "\n",
    "response = check_batch(batch_id)        # Retrieve batch information\n",
    "\n",
    "if response:\n",
    "    print(\"Batch status:\", response.status)\n",
    "    input_file_name = client.files.retrieve(response.input_file_id).filename\n",
    "    print(\"Related to input file name:\", input_file_name, \"\\n\")\n",
    "        \n",
    "    if response.status == \"completed\" and response.output_file_id:\n",
    "        output_file_id = response.output_file_id\n",
    "        print(\"Output file ID:\", output_file_id)\n",
    "\n",
    "        os.makedirs(output_file_directory, exist_ok=True)   # Ensure the output directory exists, create if not\n",
    "\n",
    "        batch_output_content = client.files.content(output_file_id)     # Retrieve content of the output file\n",
    "\n",
    "        batch_num = extract_batch_num(input_file_name)      # Extract batch number from the file name if possible\n",
    "\n",
    "         # Define output file name\n",
    "        if batch_num is not None:\n",
    "            output_file_name = f\"{output_file_name.split('.')[0]}-batch_{batch_num}.jsonl\"\n",
    "\n",
    "        output_file_path = os.path.join(output_file_directory, output_file_name)\n",
    "        \n",
    "        batch_output_content.write_to_file(output_file_path)        # Write output file content to disk\n",
    "        print(\"Output file retreived successfully:\", output_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>**Optional**</u>: Combine all jsonl files into a single file, if splitted and sent in multiple batches earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Directory containing the JSONL files\n",
    "jsonl_directory = \"./Responses\"\n",
    "output_file_name = 'responses.jsonl'\n",
    "\n",
    "# List to store combined responses\n",
    "combined_responses = []\n",
    "\n",
    "# Step 1: Combine responses from all JSONL files into one list\n",
    "for file_name in os.listdir(jsonl_directory):\n",
    "    if file_name.startswith(f\"{output_file_name}-batch_\") and file_name.endswith(\".jsonl\"):\n",
    "        file_path = os.path.join(jsonl_directory, file_name)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as jsonl_file:\n",
    "            for line in jsonl_file:\n",
    "                data = json.loads(line.strip())\n",
    "                combined_responses.append(data)\n",
    "\n",
    "print(\"Repsonses are now combined in one list.\")\n",
    "print(\"Response of the first request:\")\n",
    "print(combined_responses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Write combined responses to a new JSONL file\n",
    "output_jsonl_file = \"./Responses/responses.jsonl\"\n",
    "with open(output_jsonl_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for response in combined_responses:\n",
    "        outfile.write(json.dumps(response) + \"\\n\")\n",
    "\n",
    "print(\"Repsonses are now combined in one JSONL file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Batch Responses from JSONL File to a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "input_jsonl_file = './prompts.jsonl'\n",
    "output_jsonl_file = \"./Responses/responses.jsonl\"\n",
    "output_csv_file = \"./Responses/extracted_responses.csv\"\n",
    "\n",
    "# Dictionary to store custom IDs and corresponding message content\n",
    "custom_id_to_message = {}\n",
    "\n",
    "# Read data from the output JSONL file and populate the dictionary\n",
    "with open(output_jsonl_file, \"r\", encoding=\"utf-8\") as jsonlfile:\n",
    "    for line in jsonlfile:\n",
    "        data = json.loads(line.strip())\n",
    "        custom_id = data.get(\"custom_id\", \"\")\n",
    "        response_body = data.get(\"response\", {}).get(\"body\", {})\n",
    "        \n",
    "        if response_body:\n",
    "            assistant_response = response_body.get(\"choices\", [])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "            custom_id_to_message[custom_id] = assistant_response\n",
    "        else:\n",
    "            print(f\"No response found for custom ID: {custom_id}\")\n",
    "\n",
    "# Write data to the CSV file in the order of custom IDs from the input JSONL file\n",
    "with open(output_csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Custom ID\", \"Response\"])\n",
    "\n",
    "    with open(input_jsonl_file, \"r\", encoding=\"utf-8\") as input_jsonlfile:\n",
    "        for line in input_jsonlfile:\n",
    "            data = json.loads(line.strip())\n",
    "            custom_id = data.get(\"custom_id\", \"\")\n",
    "            message_content = custom_id_to_message.get(custom_id, \"\")\n",
    "            writer.writerow([custom_id, message_content])\n",
    "            if not message_content:\n",
    "                print(f\"No message content found for custom ID: {custom_id}\")\n",
    "\n",
    "print(\"Responses to prompts have been saved to a CSV file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
