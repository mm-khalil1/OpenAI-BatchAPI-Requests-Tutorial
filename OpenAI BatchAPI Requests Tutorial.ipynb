{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Requests with OpenAI API\n",
    "\n",
    "This notebook demonstrates how to efficiently process multiple prompts at once using OpenAI's Batch API.  \n",
    "  \n",
    "**Note**: Batch responses may take up to 24 hours to be processed by OpenAI.\n",
    "  \n",
    "Make sure to run the following cell before any other cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "\n",
    "def convert_timestamp(timestamp):\n",
    "    return datetime.fromtimestamp(timestamp) if timestamp is not None else None\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Prepare JSONL File**\n",
    "To use OpenAI's Batch API, prompts must be provided in a JSONL (JSON Lines) format.  \n",
    "Assuming you have a CSV file that includes two columns:  \n",
    "- prompts \n",
    "- IDs corresponding to each prompt (needed to retrieve its response later)  \n",
    "\n",
    "CSV file content should be structured as follows:\n",
    "```\n",
    "IDs,Prompts\n",
    "request-1,\"Once upon a time,\"\n",
    "request-2,\"Translate Good morning to French.\"\n",
    "request-3,\"Write a poem about circles.\"\n",
    "```\n",
    "then use the following code to prepare a `JSONL` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to CSV file\n",
    "prompts_csv_file = './prompts.csv'                              # Path to CSV file containing the prompts\n",
    "prompts_jsonl_file = prompts_csv_file.replace('.csv', '.jsonl')\n",
    "\n",
    "# Model configuration\n",
    "model = \"gpt-4-turbo\"\n",
    "max_tokens = 10\n",
    "temperature = 1\n",
    "system_message = \"You are a helpful assistant.\"\n",
    "\n",
    "def csv_to_jsonl(csv_file, jsonl_file, model, max_tokens=4096, temperature=1, system=\"You are a helpful assistant.\"):\n",
    "    \"\"\"Convert a CSV file to JSON Lines (JSONL) for batch requests using OpenAI API.\"\"\"\n",
    "    with open(csv_file, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        with open(jsonl_file, 'w', encoding='utf-8') as jsonlfile:\n",
    "            for row in reader:\n",
    "                custom_id = row['IDs']\n",
    "                user_message = row['Prompts']\n",
    "                data = construct_json_line(custom_id, model, user_message, system, max_tokens, temperature)\n",
    "                jsonlfile.write(json.dumps(data) + '\\n')\n",
    "\n",
    "def construct_json_line(custom_id, model, user_message, system_message, max_tokens, temperature):\n",
    "    \"\"\"Construct a JSON line for a chat completion request.\"\"\"\n",
    "    return {\n",
    "        \"custom_id\": custom_id, \n",
    "        \"method\": \"POST\", \n",
    "        \"url\": \"/v1/chat/completions\", \n",
    "        \"body\": {\n",
    "            \"model\": model, \n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": temperature,\n",
    "        }\n",
    "    }\n",
    "\n",
    "csv_to_jsonl(prompts_csv_file, prompts_jsonl_file, model, max_tokens, temperature, system_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>**Optional**</u>:\n",
    "If prompts in the JSONL file exceeds the maximum limit of tokens per day (900,000 TPD for tier 1 for instance), they can be splitted into multiple JSONL files, and then batched sequentially.  \n",
    "  \n",
    "If this error is encountered for example:  \n",
    "```\n",
    "BatchError(code=‘token_limit_exceeded’, line=None, message='Enqueued token limit reached ...\n",
    "```\n",
    "in this case, the following code can be used to split the JSONL file.  \n",
    "  \n",
    "Specify `lines_per_file` based on the number of tokens in your prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_per_file = 1000                           # Adjust as needed\n",
    "prompts_jsonl_file = './prompts.jsonl'\n",
    "splitted_prompts_dir = \"./Batch_Prompts\"        # Directory where JSONL files will be stored\n",
    "\n",
    "def split_file(input_file_path, output_dir, max_lines_per_file):\n",
    "    \"\"\"Split lines into multiple files with a specified maximum number of lines per file.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)        # Ensure the output directory exists, create if not \n",
    "    with open(input_file_path, \"r\") as infile:\n",
    "        lines = infile.readlines()\n",
    "\n",
    "    # Calculate the number of output files needed\n",
    "    num_files = (len(lines) + max_lines_per_file - 1) // max_lines_per_file\n",
    "\n",
    "    # Write lines to each output file\n",
    "    for i in range(num_files):\n",
    "        start_index = i * max_lines_per_file\n",
    "        end_index = min((i + 1) * max_lines_per_file, len(lines))\n",
    "        output_filename = f\"prompts-batch_{i+1}.jsonl\"\n",
    "        with open(os.path.join(output_dir, output_filename), \"w\") as outfile:\n",
    "            outfile.writelines(lines[start_index:end_index])\n",
    "\n",
    "split_file(prompts_jsonl_file, splitted_prompts_dir, lines_per_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Upload JSONL File(s) to OpenAI Account**\n",
    "\n",
    "There are two options to upload a file:\n",
    "\n",
    "1. **Via OpenAI Account**: Follow these steps:\n",
    "    - In OpenAI account dashboard:\n",
    "    - Navigate to [Storage](https://platform.openai.com/storage) section on the left sidebar.\n",
    "    - Click on **+ Upload** button at the top right.\n",
    "    - Select the file(s) and click on **Upload**.\n",
    "2. **Using Python Script**: Execute the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prompts_dir = \".\"       # Change it to the directory containing the JSONL file(s)\n",
    "\n",
    "def upload_file(file_path):\n",
    "    '''Upload a JSONL file and return the file ID from OpenAI's server.'''\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            file_upload_response = client.files.create(\n",
    "                file=file,\n",
    "                purpose=\"batch\"\n",
    "            )\n",
    "        return file_upload_response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# Get the list of JSONL files in the directory\n",
    "jsonl_files = [file for file in os.listdir(batch_prompts_dir) if file.endswith(\".jsonl\")]\n",
    "\n",
    "# Upload each JSONL file\n",
    "for jsonl_file in jsonl_files:\n",
    "    jsonl_batch_file_path = os.path.join(batch_prompts_dir, jsonl_file)\n",
    "    file_upload_response = upload_file(jsonl_batch_file_path)\n",
    "    if file_upload_response:\n",
    "        try:\n",
    "            input_file_id = file_upload_response.id\n",
    "            print(f\"File ID for {jsonl_file}: {input_file_id}\")\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display List of Files in OpenAI Account\n",
    "This includes uploaded files, as well as output files generated by OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    list_files = client.files.list(\n",
    "        # purpose=\"batch\"       # Specify purpose of file (batch, fine-tuning, assistant, etc).\n",
    "    )\n",
    "    for i in range(len(list_files.data)):\n",
    "        file_data = list_files.data[i]\n",
    "        print(f\"File: {file_data.id} | Purpose: {file_data.purpose:<12} | Created at: {convert_timestamp(file_data.created_at)} | File Name: {file_data.filename}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete a File\n",
    "You can delete a file by passing its file ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_file_id = \"file-xxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "try:\n",
    "    response = client.files.delete(delete_file_id)\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(e) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Create a Batch**\n",
    "\n",
    "(If you have multiple batch files to process, execute them sequentially to avoid reaching the Max Tokens per Day limit.)  \n",
    "  \n",
    "Batch requests can be created:\n",
    "\n",
    "1. **Via OpenAI Account**: Follow these steps:\n",
    "    - Access OpenAI account dashboard.\n",
    "    - Navigate to [Batch](https://platform.openai.com/batch) section on the left sidebar.\n",
    "    - Click on **+ Create** button at the top right.\n",
    "    - Upload the file and click on **Create**.\n",
    "2. **Using Python Script**: Execute the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_file_id = \"file-xxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "def create_batch(input_file_id, client):\n",
    "    \"\"\"Create a batch request and return the response.\"\"\"\n",
    "    try:\n",
    "        batch_response = client.batches.create(\n",
    "            input_file_id=input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\"\n",
    "        )\n",
    "        return batch_response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# Execute the batch creation\n",
    "create_batch_response = create_batch(input_file_id, client)\n",
    "\n",
    "# Display batch information\n",
    "if create_batch_response:\n",
    "    try:\n",
    "        file_name = client.files.retrieve(input_file_id).filename\n",
    "        print(\"Batch file name:\", file_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving file name: {e}\")\n",
    "    print(\"Batch status:\", create_batch_response.status)\n",
    "    if create_batch_response.id:\n",
    "        batch_id = create_batch_response.id\n",
    "        print(\"Batch ID:\", batch_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4: Monitor and Retrieve Batch Information**\n",
    "\n",
    "Two options to monitor a batch request:\n",
    "\n",
    "1. **Via OpenAI Account**: Follow these steps:\n",
    "    - Access OpenAI account dashboard.\n",
    "    - Navigate to [Batch](https://platform.openai.com/batch) section on the left sidebar.\n",
    "    - Click on the desired batch ID (e.g., `batch_xxxxxxxxxxxxxxxxxxxxxxxx`).\n",
    "    - Check the status.\n",
    "2. **Using Python Script**: Execute the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_id = \"batch_xxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "def check_batch(batch_id):\n",
    "    \"\"\"Retrieve batch information using the provided batch ID.\"\"\"\n",
    "    try:\n",
    "        return client.batches.retrieve(batch_id)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def print_label_and_timestamp(label, timestamp):\n",
    "    \"\"\"Prints the provided label and timestamp in a human-readable format.\"\"\"\n",
    "    print(label + \":\", convert_timestamp(timestamp)) if timestamp is not None else None\n",
    "\n",
    "# Retrieve batch information\n",
    "check_batch_response = check_batch(batch_id)\n",
    "\n",
    "# Display batch information\n",
    "if check_batch_response:\n",
    "    print(\"Batch status:\", check_batch_response.status)\n",
    "    request_counts = check_batch_response.request_counts\n",
    "    print(f\"Completed: {request_counts.completed:<6}| Failed: {request_counts.failed:<6}| Total: {request_counts.total:<6}\\n\")\n",
    "\n",
    "    if check_batch_response.errors:\n",
    "        print(\"Batch error:\", check_batch_response.errors)\n",
    "    else:\n",
    "        event_names = ['created_at', 'expires_at', 'completed_at', 'expired_at', 'failed_at']\n",
    "        for event_name in event_names:\n",
    "            print_label_and_timestamp(f\"Batch {event_name.replace('_', ' ')}\", getattr(check_batch_response, event_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display List of Batch Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    list_batches = client.batches.list(\n",
    "        limit=20    # Number of batches to display\n",
    "    )\n",
    "    for i in range(len(list_batches.data)):\n",
    "        batch_data = list_batches.data[i]\n",
    "        try:\n",
    "            input_file_name = client.files.retrieve(batch_data.input_file_id).filename\n",
    "        except Exception:\n",
    "            input_file_name = 'File is not found'\n",
    "        print(f\"Batch: {batch_data.id} | Status: {batch_data.status:<11} | Created at: {convert_timestamp(batch_data.created_at)} | Input File: {input_file_name}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<u>Cancel</u> a Batch**\n",
    "To cancel a batch:\n",
    "1. **Via OpenAI Account**: Follow these steps:\n",
    "    - Access OpenAI account dashboard.\n",
    "    - Navigate to [Batch](https://platform.openai.com/batch) section on the left sidebar.\n",
    "    - Click on the desired batch ID (e.g., `batch_xxxxxxxxxxxxxxxxxxxxxxxx`).\n",
    "    - Click on `Cancel`.\n",
    "2. **Using Python Script**: Execute the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id = \"batch_xxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "def cancel_batch(batch_id):\n",
    "    \"\"\"Cancel a batch with the provided batch ID and return the cancellation response.\"\"\"\n",
    "    try:\n",
    "        return client.batches.cancel(batch_id)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "\n",
    "cancel_batch_response = cancel_batch(batch_id)\n",
    "\n",
    "if cancel_batch_response:\n",
    "    print(\"Batch status:\", cancel_batch_response.status)\n",
    "    if cancel_batch_response.errors:\n",
    "        print(\"Batch error:\", cancel_batch_response.errors)\n",
    "    else:\n",
    "        if cancel_batch_response.cancelled_at is not None:\n",
    "            print(\"Batch canceled at:\", convert_timestamp(cancel_batch_response.cancelled_at))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 5: Retrieve Output File Content**\n",
    "\n",
    "Again there are two options to retrieve batch responses as a JSONL file:\n",
    "\n",
    "1. **Via OpenAI Account**: Follow these steps:\n",
    "    - Access OpenAI account dashboard.\n",
    "    - Navigate to [Storage](https://platform.openai.com/storage) section on the left sidebar.\n",
    "    - Click on the JSONL file name with the desired batch ID (e.g., `batch_xxxxxxxxxxxxxxxxxxxxxxxx_output.jsonl`).\n",
    "    - Download the JSONL file\n",
    "2. **Using Python Script**: Execute the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "response_files_dir = \"./Responses\"         # Directory where the JSONL file(s) wil be stored\n",
    "responses_file_name = 'responses.jsonl'    # Desired name of the responses file\n",
    "# batch_id = \"batch_xxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "def check_batch(batch_id):\n",
    "    \"\"\"Retrieve batch information using the provided batch ID.\"\"\"\n",
    "    try:\n",
    "        return client.batches.retrieve(batch_id)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def extract_batch_num(file_name):\n",
    "    \"\"\"A function to extract batch number from file name if possible\"\"\"\n",
    "    try:\n",
    "        integers = re.findall(r'\\d+', file_name)     # Find all integers in the string\n",
    "        return int(integers[-1])                # Extract the last number\n",
    "    except (IndexError, ValueError):\n",
    "        return None\n",
    "\n",
    "check_batch_response = check_batch(batch_id)        # Retrieve batch information\n",
    "\n",
    "if check_batch_response:\n",
    "    print(\"Batch status:\", check_batch_response.status)\n",
    "\n",
    "    try:\n",
    "        input_file_name = client.files.retrieve(check_batch_response.input_file_id).filename\n",
    "        print(\"Related to input file name:\", input_file_name, \"\\n\")\n",
    "    except Exception:\n",
    "        input_file_name = \"\"\n",
    "        print(\"Input file is not found in files list in OpenAI\\n\")\n",
    "\n",
    "    if check_batch_response.status == \"completed\" and check_batch_response.output_file_id:\n",
    "        output_file_id = check_batch_response.output_file_id\n",
    "        print(\"Output file ID:\", output_file_id)\n",
    "\n",
    "        os.makedirs(response_files_dir, exist_ok=True)   # Ensure the output directory exists, create if not\n",
    "\n",
    "        batch_output_content = client.files.content(output_file_id)     # Retrieve content of the output file\n",
    "\n",
    "        batch_num = extract_batch_num(input_file_name)      # Extract batch number from the file name if possible\n",
    "\n",
    "         # Define output file name\n",
    "        if batch_num is not None:\n",
    "            responses_file_name = f\"{responses_file_name.split('.')[0]}-batch_{batch_num}.jsonl\"\n",
    "\n",
    "        output_file_path = os.path.join(response_files_dir, responses_file_name)\n",
    "        \n",
    "        batch_output_content.write_to_file(output_file_path)        # Write output file content to disk\n",
    "        print(\"Content of batch response retrieved successfully:\", responses_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>**Optional**</u>:  \n",
    "Combine all jsonl files into a single file, if splitted and sent in multiple batches earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "response_files_dir = \"./Responses\"          # Directory containing the JSONL files\n",
    "first_file = 'responses-batch_1.jsonl'      # First file in the sequence (e.g., 'responses-batch_1.jsonl')\n",
    "                                            # Expected sequence format: 'responses-batch_{number}.jsonl'\n",
    "responses_jsonl_file = \"./Responses/responses.jsonl\" # Desired output JSONL file path\n",
    "\n",
    "def extract_prefix_before_last_num(text):\n",
    "    \"\"\"Extracts the prefix before the last number in the given text.\"\"\"\n",
    "    integers = re.findall(r'\\d+', text)             # Find all integers in the string\n",
    "    if not integers:\n",
    "        raise ValueError(\"No number found in the input text.\")\n",
    "    last_integer = int(integers[-1])                # Extract the last number\n",
    "    return text.rsplit(str(last_integer), 1)[0]     # Extract the prefix before the last number\n",
    "\n",
    "def combine_jsonl_files(response_files_dir, output_file, first_file):\n",
    "    \"\"\"Combine JSONL files in the input directory and write to the output JSONL file.\"\"\"\n",
    "    if not first_file:\n",
    "        raise ValueError(\"The 'first_file' argument must be provided to determine the prefix.\")\n",
    "    file_prefix = extract_prefix_before_last_num(first_file)\n",
    "    if not os.path.isdir(response_files_dir):\n",
    "        raise FileNotFoundError(f\"Input directory '{response_files_dir}' does not exist.\")\n",
    "    if not os.listdir(response_files_dir):\n",
    "        raise FileNotFoundError(f\"Input directory '{response_files_dir}' is empty.\")\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as out_jsonl:\n",
    "        for file_name in os.listdir(response_files_dir):\n",
    "            if file_name.startswith(file_prefix) and file_name.endswith(\".jsonl\"):\n",
    "                file_path = os.path.join(response_files_dir, file_name)\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as in_jsonl:\n",
    "                    for line in in_jsonl:\n",
    "                        out_jsonl.write(line)\n",
    "    print(\"Responses are now combined in one JSONL file.\")\n",
    "\n",
    "combine_jsonl_files(response_files_dir, responses_jsonl_file, first_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extract Batch Responses from JSONL File to a CSV File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_jsonl_file = './prompts.jsonl'\n",
    "responses_jsonl_file = \"./Responses/responses.jsonl\"\n",
    "responses_csv_file = \"./Responses/extracted_responses.csv\"\n",
    "\n",
    "# Dictionary to store custom IDs and corresponding message content\n",
    "custom_id_to_message = {}\n",
    "\n",
    "# Read data from the output JSONL file and populate the dictionary\n",
    "with open(responses_jsonl_file, \"r\", encoding=\"utf-8\") as jsonlfile:\n",
    "    for line in jsonlfile:\n",
    "        data = json.loads(line.strip())\n",
    "        custom_id = data.get(\"custom_id\", \"\")\n",
    "        response_body = data.get(\"response\", {}).get(\"body\", {})\n",
    "        \n",
    "        if response_body:\n",
    "            assistant_response = response_body.get(\"choices\", [])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "            custom_id_to_message[custom_id] = assistant_response\n",
    "        else:\n",
    "            print(f\"No response found for custom ID: {custom_id}\")\n",
    "\n",
    "# Write data to the CSV file in the order of custom IDs from the input JSONL file\n",
    "with open(responses_csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Custom ID\", \"Response\"])\n",
    "\n",
    "    with open(prompts_jsonl_file, \"r\", encoding=\"utf-8\") as input_jsonlfile:\n",
    "        for line in input_jsonlfile:\n",
    "            data = json.loads(line.strip())\n",
    "            custom_id = data.get(\"custom_id\", \"\")\n",
    "            message_content = custom_id_to_message.get(custom_id, \"\")\n",
    "            writer.writerow([custom_id, message_content])\n",
    "            if not message_content:\n",
    "                print(f\"No message content found for custom ID: {custom_id}\")\n",
    "\n",
    "print(\"Responses to prompts have been saved to a CSV file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
